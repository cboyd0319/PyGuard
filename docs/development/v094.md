# PyGuard v0.9.4 - AI/ML Auto-Fix Group C: External Content Injection

**Version:** 0.9.4
**Phase:** Phase 6 - Auto-Fix & Remediation (Group C Implementation)
**Target:** Implement auto-fixes for indirect prompt injection and external content manipulation
**Status:** üéØ Planning
**Started:** 2025-10-27
**Completed:** TBD

## Progress Overview

**Previous State (v0.9.3):** 31/510 auto-fixes (6%)
**Current State:** 31/510 auto-fixes (6%) - Planning Group C
**Target State:** To be determined based on Group C scope
**Phase 1 Progress:** 31/80 fixes complete (39%)

## Phase 6.3 Objective

Implement **Group C: Indirect Prompt Injection & External Content Manipulation** auto-fixes covering external data sources that can be poisoned.

### Goal
According to the AI/ML plan (docs/copilot/ai_ml.md), Phase 1.1 includes:
- **Indirect Prompt Injection (15 checks)** - AIML031-AIML045

Implement automatic remediation for external content security:
- URL-based injection (AIML031)
- Document poisoning (AIML032)
- Image-based prompt injection (AIML033)
- API response injection (AIML034)
- Database content injection (AIML035)
- File upload injection vectors (AIML036)
- Email content injection (AIML037)
- Social media scraping injection (AIML038)
- RAG poisoning (AIML039)
- Vector database injection (AIML040)
- Knowledge base tampering (AIML041)
- Citation manipulation (AIML042)
- Search result poisoning (AIML043)
- User profile injection (AIML044)
- Conversation history injection (AIML045)

## Current Implementation Status

### Completed Auto-Fixes (31/80 Phase 1)

#### Foundation Fixes (17 fixes) ‚úÖ
- ‚úÖ PyTorch model loading security
- ‚úÖ Hugging Face trust parameters
- ‚úÖ API security basics
- ‚úÖ GPU memory limits
- ‚úÖ Model versioning
- ‚úÖ Basic prompt injection

#### Group A: Delimiter & Encoding Attacks (8 fixes) ‚úÖ
- ‚úÖ AIML012: Unicode/homoglyph injection
- ‚úÖ AIML013: Role confusion attacks (DAN mode)
- ‚úÖ AIML014: Instruction concatenation
- ‚úÖ AIML016: Markdown injection
- ‚úÖ AIML017: XML/JSON injection
- ‚úÖ AIML018: SQL comment injection
- ‚úÖ AIML022: Base64 injection
- ‚úÖ AIML023: ROT13 obfuscation

#### Group B: Context & Token Manipulation (6 fixes) ‚úÖ
- ‚úÖ AIML019: Escape sequence injection
- ‚úÖ AIML020: Token stuffing
- ‚úÖ AIML021: Recursive prompt injection
- ‚úÖ AIML026: Template literal injection
- ‚úÖ AIML027: F-string injection
- ‚úÖ AIML028: Variable substitution

### Group C: External Content Injection (15 checks) üéØ NEXT

**Detection Status:** 
- ‚úÖ Detection rules exist for AIML031-AIML045 in `pyguard/lib/ai_ml_security.py`
- ‚ùå Auto-fix functions NOT implemented yet

**Implementation Plan:**

#### High-Priority Fixes (6 fixes to start)

**Fix 1: AIML031 - URL-Based Injection**
- [ ] Implement `_fix_url_based_injection` function
- [ ] Detect unvalidated URL content used in prompts
- [ ] Add content sanitization warnings
- [ ] Validate URL sources before using in LLM input
- [ ] Write 15+ unit tests

**Fix 2: AIML034 - API Response Injection**
- [ ] Implement `_fix_api_response_injection` function
- [ ] Detect 3rd party API responses used directly in prompts
- [ ] Add response validation warnings
- [ ] Check for sanitization of external API data
- [ ] Write 15+ unit tests

**Fix 3: AIML035 - Database Content Injection**
- [ ] Implement `_fix_database_content_injection` function
- [ ] Detect database queries used directly in prompts
- [ ] Add query result sanitization warnings
- [ ] Validate database content before LLM input
- [ ] Write 15+ unit tests

**Fix 4: AIML039 - RAG Poisoning**
- [ ] Implement `_fix_rag_poisoning` function
- [ ] Detect retrieval-augmented generation without validation
- [ ] Add document verification warnings
- [ ] Check for embedding/retrieval security
- [ ] Write 15+ unit tests

**Fix 5: AIML040 - Vector Database Injection**
- [ ] Implement `_fix_vector_database_injection` function
- [ ] Detect vector DB queries used in prompts
- [ ] Add vector store sanitization warnings
- [ ] Validate retrieved embeddings
- [ ] Write 15+ unit tests

**Fix 6: AIML045 - Conversation History Injection**
- [ ] Implement `_fix_conversation_history_injection` function
- [ ] Detect unvalidated conversation history
- [ ] Add history sanitization warnings
- [ ] Check for state management security
- [ ] Write 15+ unit tests

## Implementation Strategy

### Phase C.1: Core External Content (6 fixes)
Focus on the most common and critical external content vectors:
1. URL-based injection (web content)
2. API response injection (3rd party data)
3. Database content injection (stored data)
4. RAG poisoning (retrieval systems)
5. Vector database injection (embeddings)
6. Conversation history injection (state)

**Rationale:** These 6 cover the most prevalent real-world attack vectors in modern LLM applications, especially those using RAG and conversational AI patterns.

### Phase C.2: Document & Media (4 fixes) - Future
- Document poisoning (AIML032)
- Image-based injection (AIML033)
- File upload vectors (AIML036)
- Email content injection (AIML037)

### Phase C.3: Social & Knowledge (5 fixes) - Future
- Social media scraping (AIML038)
- Knowledge base tampering (AIML041)
- Citation manipulation (AIML042)
- Search result poisoning (AIML043)
- User profile injection (AIML044)

## Testing Strategy

### Per Fix Requirements (Minimum 15 tests)

1. **Basic Detection (3 tests)**
   - Vulnerable external content pattern
   - Safe validation pattern
   - Edge cases

2. **Fix Application (3 tests)**
   - Comment insertion correctness
   - Warning message accuracy
   - Multiple occurrences

3. **Framework Coverage (3 tests)**
   - OpenAI API with external content
   - Anthropic API with RAG
   - Generic LLM with vector stores

4. **Integration (3 tests)**
   - Real-world RAG patterns
   - API response handling
   - Database query results

5. **Regression (3 tests)**
   - Idempotency validation
   - No false positives
   - Preserves functionality

### Expected Test Class

```python
class TestGroupCExternalContentFixes:
    """Test Group C: External Content Injection auto-fixes (AIML031-045)."""
    
    def test_url_based_injection_fix(self, tmp_path):
        """Test AIML031: URL-based injection detection."""
        # Test unvalidated URL content in prompts
        
    def test_api_response_injection_fix(self, tmp_path):
        """Test AIML034: API response injection detection."""
        # Test 3rd party API data in prompts
        
    def test_database_content_injection_fix(self, tmp_path):
        """Test AIML035: Database content injection detection."""
        # Test database query results in prompts
        
    def test_rag_poisoning_fix(self, tmp_path):
        """Test AIML039: RAG poisoning detection."""
        # Test retrieval-augmented generation security
        
    def test_vector_database_injection_fix(self, tmp_path):
        """Test AIML040: Vector database injection detection."""
        # Test vector store queries in prompts
        
    def test_conversation_history_injection_fix(self, tmp_path):
        """Test AIML045: Conversation history injection."""
        # Test conversation state management
        
    def test_group_c_integration(self, tmp_path):
        """Test all Group C fixes working together."""
        # Comprehensive integration test
```

## Success Metrics

**Technical Targets:**
- üéØ **6 new auto-fixes implemented** (Phase C.1)
- üéØ **90+ new unit tests** (15 per fix)
- üéØ **100% test pass rate**
- üéØ **37/80 Phase 1 progress** (46%)

**Quality Targets:**
- üéØ All fixes preserve code functionality
- üéØ All fixes include educational comments
- üéØ All fixes have OWASP references (OWASP LLM01)
- üéØ <5% false positive rate

## Timeline

**Estimated Duration:** 1.5-2 weeks for Group C Phase 1 (6 fixes)
**Current Week:** Week 3-4 of auto-fix implementation

**Weekly Breakdown:**
- **Week 1 (Days 1-5):**
  - Day 1-2: AIML031 (URL-based injection) + AIML034 (API response)
  - Day 3-4: AIML035 (Database content) + AIML039 (RAG poisoning)
  - Day 5: AIML040 (Vector database)
  
- **Week 2 (Days 6-10):**
  - Day 6: AIML045 (Conversation history)
  - Day 7-8: Write comprehensive tests (90+ tests)
  - Day 9: Integration testing & validation
  - Day 10: Documentation & polish

## Implementation Steps

### Immediate Actions
1. [ ] Create `_fix_url_based_injection` in `pyguard/lib/ai_ml_security.py`
2. [ ] Create `_fix_api_response_injection` 
3. [ ] Create `_fix_database_content_injection`
4. [ ] Create `_fix_rag_poisoning`
5. [ ] Create `_fix_vector_database_injection`
6. [ ] Create `_fix_conversation_history_injection`
7. [ ] Create test class `TestGroupCExternalContentFixes` in `tests/unit/test_ai_ml_security.py`
8. [ ] Write 90+ comprehensive tests (15 per fix)
9. [ ] Run full test suite and validate
10. [ ] Update v094.md to mark as complete
11. [ ] Create v095.md for next phase

## Architecture Notes

### Auto-Fix Pattern for External Content

```python
def _fix_<external_source>_injection(self, content: str) -> str:
    """
    Validate external content before using in LLM prompts.
    
    Classification: SAFE
    - Detects unvalidated external content
    - Adds validation warnings
    - Prevents injection via external sources
    
    Before: prompt = f"Process: {fetch_url(url)}"
    After:  # PyGuard: Validate external content before use [AIML0XX]
            # Sanitize: URL content, API responses, etc.
    
    Reference: AIML0XX, OWASP LLM01
    """
    fix_id = "external_content_injection"
    if not self.safety_classifier.should_apply_fix(fix_id, self.allow_unsafe):
        return content
    
    # Check for external content patterns
    external_patterns = [
        'fetch', 'requests.get', 'urllib', 'api.call',
        'db.query', 'cursor.execute', 'retrieve', 'search',
        'vector_store', 'embeddings', 'history'
    ]
    
    if any(pattern in content for pattern in external_patterns):
        # Add validation warning comments
        # Insert sanitization recommendations
        pass
    
    return content
```

## References

- OWASP LLM Top 10 2023 (LLM01: Prompt Injection)
- MITRE ATLAS Framework (AML.T0051: LLM Prompt Injection)
- RAG Security Best Practices
- Vector Database Security Guidelines
- Conversational AI Security Patterns
- `docs/copilot/ai_ml.md` - Complete AI/ML plan (Phase 1.1)
- `docs/development/v093.md` - Previous phase (Group B)

---

**Previous Phase:** See `v093.md` for Group B (Context & Token Manipulation)
**Current Phase:** üéØ Planning Group C (External Content Injection)
**Next Phase:** See `v095.md` for next implementation phase

---

**Status:** üéØ Planning - Defining Group C scope and implementation strategy
**Achievement:** 31/80 Phase 1 fixes complete (39%)
**Focus:** External content security (URL, API, DB, RAG, Vector stores, Conversations)
