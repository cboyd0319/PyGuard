# PyGuard v0.9.5 - AI/ML Auto-Fix Group D: LLM API Security

**Version:** 0.9.5
**Phase:** Phase 6 - Auto-Fix & Remediation (Group D Implementation)
**Target:** Implement auto-fixes for LLM API security vulnerabilities
**Status:** ğŸ¯ IN PROGRESS
**Started:** 2025-10-27
**Completed:** TBD

## Progress Overview

**Previous State (v0.9.4):** 37/510 auto-fixes (7%)
**Current State:** 37/510 auto-fixes (7%)
**Target State:** 47/510 auto-fixes (9%)
**Phase 1 Progress:** 37/80 fixes complete (46%)

## Phase 6.4 Objective

Implement **Group D: LLM API Security** auto-fixes covering API-specific vulnerabilities in LLM integrations.

### Goal
According to the AI/ML plan (docs/copilot/ai_ml.md), Phase 1.1 includes:
- **LLM API Security (15 checks)** - AIML046-AIML060

Implement automatic remediation for LLM API security:
- Missing rate limiting on LLM API calls (AIML046) âœ… Already implemented
- Unvalidated temperature/top_p parameters (AIML047)
- Max_tokens manipulation (DoS) (AIML048)
- Streaming response injection (AIML049)
- Function calling injection (AIML050)
- Tool use parameter tampering (AIML051)
- System message manipulation via API (AIML052)
- Model selection bypass (AIML053)
- API key exposure in client code (AIML054) âœ… Already implemented
- Hardcoded model names (version lock-in) (AIML055)
- Missing timeout configurations (AIML056) âœ… Already implemented
- Unhandled API errors (info disclosure) (AIML057) âœ… Already implemented
- Token counting bypass (AIML058)
- Cost overflow attacks (AIML059)
- Multi-turn conversation state injection (AIML060)

## Current Implementation Status

### Completed Auto-Fixes (37/80 Phase 1)

#### Foundation Fixes (17 fixes) âœ…
- âœ… PyTorch model loading security
- âœ… Hugging Face trust parameters
- âœ… API security basics (rate limiting, key exposure, timeout, error handling)
- âœ… GPU memory limits
- âœ… Model versioning
- âœ… Basic prompt injection

#### Group A: Delimiter & Encoding Attacks (8 fixes) âœ…
- âœ… AIML012: Unicode/homoglyph injection
- âœ… AIML013: Role confusion attacks
- âœ… AIML014: Instruction concatenation
- âœ… AIML016: Markdown injection
- âœ… AIML017: XML/JSON injection
- âœ… AIML018: SQL comment injection
- âœ… AIML022: Base64 injection
- âœ… AIML023: ROT13 obfuscation

#### Group B: Context & Token Manipulation (6 fixes) âœ…
- âœ… AIML019: Escape sequence injection
- âœ… AIML020: Token stuffing
- âœ… AIML021: Recursive prompt injection
- âœ… AIML026: Template literal injection
- âœ… AIML027: F-string injection
- âœ… AIML028: Variable substitution

#### Group C: External Content Injection (6 fixes) âœ…
- âœ… AIML031: URL-based injection
- âœ… AIML034: API response injection
- âœ… AIML035: Database content injection
- âœ… AIML039: RAG poisoning
- âœ… AIML040: Vector database injection
- âœ… AIML045: Conversation history injection

### Group D: LLM API Security (15 checks) ğŸ¯ CURRENT

**Detection Status:** 
- âœ… Detection rules exist for AIML046-AIML060 in `pyguard/lib/ai_ml_security.py`
- âš ï¸ 4 auto-fix functions already implemented (rate limiting, key exposure, timeout, error handling)
- âŒ 10 auto-fix functions need implementation

**Implementation Plan:**

#### Already Implemented (4 fixes) âœ…
- âœ… AIML046: Missing rate limiting - `_fix_llm_rate_limiting` exists
- âœ… AIML054: API key exposure - `_fix_api_key_exposure` exists
- âœ… AIML056: Missing timeout - `_fix_missing_timeout` exists
- âœ… AIML057: Unhandled API errors - `_fix_unhandled_api_errors` exists

#### High-Priority Fixes (10 fixes) - TO IMPLEMENT ğŸ¯

**Fix 1: AIML047 - Unvalidated Temperature/Top_p Parameters**
- âš ï¸ Partial implementation exists as `_fix_api_parameter_validation`
- ğŸ¯ Extend to cover temperature, top_p, top_k range validation
- ğŸ¯ Detect missing parameter validation
- ğŸ¯ Add safety warnings for extreme values
- ğŸ¯ Write unit tests (2 tests)

**Fix 2: AIML048 - Max_tokens Manipulation (DoS)**
- ğŸ¯ Implement `_fix_max_tokens_manipulation` function
- ğŸ¯ Detect missing max_tokens limits
- ğŸ¯ Add DoS prevention warnings
- ğŸ¯ Validate token budgets
- ğŸ¯ Write unit tests (2 tests)

**Fix 3: AIML049 - Streaming Response Injection**
- ğŸ¯ Implement `_fix_streaming_response_injection` function
- ğŸ¯ Detect unvalidated streaming responses
- ğŸ¯ Add stream validation warnings
- ğŸ¯ Check for partial response handling
- ğŸ¯ Write unit tests (2 tests)

**Fix 4: AIML050 - Function Calling Injection**
- ğŸ¯ Implement `_fix_function_calling_injection` function
- ğŸ¯ Detect unsafe function/tool calls
- ğŸ¯ Add function schema validation warnings
- ğŸ¯ Check for function execution security
- ğŸ¯ Write unit tests (2 tests)

**Fix 5: AIML051 - Tool Use Parameter Tampering**
- ğŸ¯ Implement `_fix_tool_use_tampering` function
- ğŸ¯ Detect unvalidated tool parameters
- ğŸ¯ Add tool input validation warnings
- ğŸ¯ Check for parameter sanitization
- ğŸ¯ Write unit tests (2 tests)

**Fix 6: AIML052 - System Message Manipulation via API**
- ğŸ¯ Implement `_fix_system_message_manipulation` function
- ğŸ¯ Detect mutable system messages
- ğŸ¯ Add system prompt protection warnings
- ğŸ¯ Check for message role validation
- ğŸ¯ Write unit tests (2 tests)

**Fix 7: AIML053 - Model Selection Bypass**
- ğŸ¯ Implement `_fix_model_selection_bypass` function
- ğŸ¯ Detect unvalidated model names
- ğŸ¯ Add model whitelist warnings
- ğŸ¯ Check for model version control
- ğŸ¯ Write unit tests (2 tests)

**Fix 8: AIML055 - Hardcoded Model Names**
- ğŸ¯ Implement `_fix_hardcoded_model_names` function
- ğŸ¯ Detect hardcoded model strings
- ğŸ¯ Add configuration warnings
- ğŸ¯ Suggest environment variables
- ğŸ¯ Write unit tests (2 tests)

**Fix 9: AIML058 - Token Counting Bypass**
- ğŸ¯ Implement `_fix_token_counting_bypass` function
- ğŸ¯ Detect missing token counting
- ğŸ¯ Add token tracking warnings
- ğŸ¯ Check for context window validation
- ğŸ¯ Write unit tests (2 tests)

**Fix 10: AIML059 - Cost Overflow Attacks**
- ğŸ¯ Implement `_fix_cost_overflow_attacks` function
- ğŸ¯ Detect missing cost controls
- ğŸ¯ Add budget limit warnings
- ğŸ¯ Check for usage monitoring
- ğŸ¯ Write unit tests (2 tests)

**Total New Tests:** 21 tests (20 individual + 1 integration test)

## Implementation Strategy

### Phase D.1: Parameter Validation (3 fixes)
Focus on API parameter security:
1. Unvalidated temperature/top_p parameters (AIML047)
2. Max_tokens manipulation (AIML048)
3. Token counting bypass (AIML058)

**Rationale:** Parameter validation is foundational for LLM API security and prevents most DoS attacks.

### Phase D.2: Function & Tool Security (3 fixes)
Focus on function calling and tool use:
4. Function calling injection (AIML050)
5. Tool use parameter tampering (AIML051)
6. Streaming response injection (AIML049)

**Rationale:** Function calling is a critical attack vector in agent-based LLM applications.

### Phase D.3: Model & Message Security (4 fixes)
Focus on model selection and message handling:
7. System message manipulation (AIML052)
8. Model selection bypass (AIML053)
9. Hardcoded model names (AIML055)
10. Cost overflow attacks (AIML059)

**Rationale:** Model and message integrity are essential for production LLM deployments.

## Testing Strategy

### Per Fix Requirements (Minimum 15 tests)

1. **Basic Detection (3 tests)**
   - Vulnerable API pattern
   - Safe validation pattern
   - Edge cases

2. **Fix Application (3 tests)**
   - Comment insertion correctness
   - Warning message accuracy
   - Multiple occurrences

3. **Framework Coverage (3 tests)**
   - OpenAI API patterns
   - Anthropic API patterns
   - Generic LLM APIs

4. **Integration (3 tests)**
   - Real-world API usage
   - Parameter combinations
   - Multi-API scenarios

5. **Regression (3 tests)**
   - Idempotency validation
   - No false positives
   - Preserves functionality

### Expected Test Class

```python
class TestGroupDLLMAPISecurityFixes:
    """Test Group D: LLM API Security auto-fixes (AIML046-060)."""
    
    def test_temperature_validation_fix(self, tmp_path):
        """Test AIML047: Temperature/top_p parameter validation."""
        # Test unvalidated API parameters
        
    def test_max_tokens_manipulation_fix(self, tmp_path):
        """Test AIML048: Max_tokens DoS prevention."""
        # Test missing token limits
        
    def test_streaming_response_injection_fix(self, tmp_path):
        """Test AIML049: Streaming response security."""
        # Test unvalidated streaming
        
    def test_function_calling_injection_fix(self, tmp_path):
        """Test AIML050: Function calling security."""
        # Test unsafe function calls
        
    def test_tool_use_tampering_fix(self, tmp_path):
        """Test AIML051: Tool use parameter validation."""
        # Test unvalidated tool parameters
        
    def test_system_message_manipulation_fix(self, tmp_path):
        """Test AIML052: System message protection."""
        # Test mutable system prompts
        
    def test_model_selection_bypass_fix(self, tmp_path):
        """Test AIML053: Model selection validation."""
        # Test unvalidated model names
        
    def test_hardcoded_model_names_fix(self, tmp_path):
        """Test AIML055: Hardcoded model detection."""
        # Test hardcoded model strings
        
    def test_token_counting_bypass_fix(self, tmp_path):
        """Test AIML058: Token counting validation."""
        # Test missing token tracking
        
    def test_cost_overflow_attacks_fix(self, tmp_path):
        """Test AIML059: Cost control validation."""
        # Test missing cost controls
        
    def test_group_d_integration(self, tmp_path):
        """Test all Group D fixes working together."""
        # Comprehensive integration test
```

## Success Metrics

**Technical Targets:**
- ğŸ¯ **10 new auto-fixes implemented** (Group D)
- ğŸ¯ **21 unit tests** (2 per fix + 1 integration test)
- ğŸ¯ **100% test pass rate** (all AI/ML tests passing)
- ğŸ¯ **47/80 Phase 1 progress** (59% complete)

**Quality Targets:**
- ğŸ¯ All fixes preserve code functionality
- ğŸ¯ All fixes include educational comments
- ğŸ¯ All fixes have OWASP references (OWASP LLM01, LLM02, CWE-770)
- ğŸ¯ <5% false positive rate (AST-based detection)

## Timeline

**Estimated Duration:** 1.5-2 weeks for Group D (10 fixes)
**Current Status:** Planning phase
**Next Steps:** Implement Phase D.1 (Parameter Validation)

**Breakdown:**
- Phase D.1: 3-4 days (3 parameter validation fixes)
- Phase D.2: 3-4 days (3 function/tool security fixes)
- Phase D.3: 4-5 days (4 model/message security fixes)
- Testing & Integration: 2-3 days
- Documentation & Review: 1-2 days

## Implementation Steps

### Immediate Actions
1. ğŸ¯ Create `_fix_temperature_validation` in `pyguard/lib/ai_ml_security.py`
2. ğŸ¯ Create `_fix_max_tokens_manipulation`
3. ğŸ¯ Create `_fix_streaming_response_injection`
4. ğŸ¯ Create `_fix_function_calling_injection`
5. ğŸ¯ Create `_fix_tool_use_tampering`
6. ğŸ¯ Create `_fix_system_message_manipulation`
7. ğŸ¯ Create `_fix_model_selection_bypass`
8. ğŸ¯ Create `_fix_hardcoded_model_names`
9. ğŸ¯ Create `_fix_token_counting_bypass`
10. ğŸ¯ Create `_fix_cost_overflow_attacks`
11. ğŸ¯ Create test class `TestGroupDLLMAPISecurityFixes` in `tests/unit/test_ai_ml_security.py`
12. ğŸ¯ Write 21 comprehensive tests (2 per fix + integration)
13. ğŸ¯ Run full test suite and validate
14. ğŸ¯ Update v095.md to mark as complete
15. ğŸ¯ Create v096.md for next phase

## Architecture Notes

### Auto-Fix Pattern for LLM API Security

```python
def _fix_<api_vulnerability>(self, content: str) -> str:
    """
    Validate LLM API parameters and usage patterns.
    
    Classification: SAFE
    - Detects unsafe API configurations
    - Adds validation warnings
    - Prevents DoS and injection attacks
    
    Before: response = openai.ChatCompletion.create(temperature=2.5)
    After:  # PyGuard: Validate API parameters [AIML0XX]
            # Ensure: 0.0 <= temperature <= 2.0
            response = openai.ChatCompletion.create(
                temperature=min(2.0, max(0.0, temperature)),
                max_tokens=1000  # Prevent DoS
            )
    
    Reference: AIML0XX, OWASP LLM02
    """
    fix_id = "api_security_<specific>"
    if not self.safety_classifier.should_apply_fix(fix_id, self.allow_unsafe):
        return content
    
    # Check for API security patterns
    api_patterns = [
        'openai.ChatCompletion.create', 'anthropic.messages.create',
        'temperature', 'top_p', 'max_tokens', 'stream',
        'functions', 'tools', 'function_call'
    ]
    
    if any(pattern in content for pattern in api_patterns):
        # Add validation warning comments
        # Insert parameter validation recommendations
        pass
    
    return content
```

## References

- OWASP LLM Top 10 2023 (LLM02: Insecure Output Handling, LLM07: Insecure Plugin Design)
- MITRE ATLAS Framework (AML.T0051: LLM Prompt Injection)
- CWE-770: Allocation of Resources Without Limits or Throttling
- CWE-20: Improper Input Validation
- OpenAI API Security Best Practices
- Anthropic Claude API Security Guidelines
- `docs/copilot/ai_ml.md` - Complete AI/ML plan (Phase 1.1)
- `docs/development/v094.md` - Previous phase (Group C)

---

**Previous Phase:** See `v094.md` for Group C (External Content Injection)
**Current Phase:** ğŸ¯ Implementing Group D (LLM API Security)
**Next Phase:** See `v096.md` for Group E (Output Validation)

---

**Status:** ğŸ¯ IN PROGRESS - Planning Group D implementation
**Achievement:** 37/80 Phase 1 fixes complete (46%)
**Focus:** LLM API security - parameters, functions, tools, model selection
**Impact:** Production LLM application security coverage
