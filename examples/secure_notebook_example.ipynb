{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Secure Jupyter Notebook Best Practices\n",
        "\n",
        "This notebook demonstrates security best practices for Jupyter notebooks, showing how to avoid common vulnerabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Secure Credential Management\n",
        "\n",
        "✅ **GOOD**: Use environment variables for secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Retrieve credentials securely\n",
        "api_key = os.getenv('API_KEY')\n",
        "database_url = os.getenv('DATABASE_URL')\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"API_KEY not found in environment variables\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Safe Data Loading with Validation\n",
        "\n",
        "✅ **GOOD**: Validate data types and schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify expected data types\n",
        "dtype_spec = {\n",
        "    'id': 'int64',\n",
        "    'name': 'string',\n",
        "    'age': 'int64',\n",
        "    'score': 'float64'\n",
        "}\n",
        "\n",
        "# Load data with type validation\n",
        "df = pd.read_csv('data.csv', dtype=dtype_spec)\n",
        "\n",
        "# Additional validation\n",
        "assert df['age'].min() >= 0, \"Age cannot be negative\"\n",
        "assert df['age'].max() <= 120, \"Age seems unrealistic\"\n",
        "\n",
        "print(f\"Loaded {len(df)} rows with validated schema\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Secure Model Loading\n",
        "\n",
        "✅ **GOOD**: Verify model integrity before loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import torch\n",
        "\n",
        "# Known good checksum (from trusted source)\n",
        "EXPECTED_CHECKSUM = \"abc123...\"  # Replace with actual checksum\n",
        "\n",
        "def verify_model_integrity(model_path: str, expected_checksum: str) -> bool:\n",
        "    \"\"\"Verify model file integrity using SHA-256 checksum.\"\"\"\n",
        "    with open(model_path, 'rb') as f:\n",
        "        file_hash = hashlib.sha256(f.read()).hexdigest()\n",
        "    return file_hash == expected_checksum\n",
        "\n",
        "# Verify before loading\n",
        "model_path = 'model.pth'\n",
        "if verify_model_integrity(model_path, EXPECTED_CHECKSUM):\n",
        "    model = torch.load(model_path)\n",
        "    print(\"Model loaded successfully\")\n",
        "else:\n",
        "    raise ValueError(\"Model integrity check failed - possible tampering\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Safe Command Execution\n",
        "\n",
        "✅ **GOOD**: Use subprocess with argument lists (shell=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "def safe_file_operation(filename: str) -> str:\n",
        "    \"\"\"Safely read a file using validated paths.\"\"\"\n",
        "    # Validate filename (no path traversal)\n",
        "    safe_filename = Path(filename).name\n",
        "    safe_path = Path('/safe/directory') / safe_filename\n",
        "    \n",
        "    # Use subprocess with argument list (not shell)\n",
        "    result = subprocess.run(\n",
        "        ['cat', str(safe_path)],\n",
        "        shell=False,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        check=True\n",
        "    )\n",
        "    \n",
        "    return result.stdout\n",
        "\n",
        "# Usage\n",
        "# content = safe_file_operation('data.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Safe HTML Display\n",
        "\n",
        "✅ **GOOD**: Escape user input before HTML display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Text\n",
        "import html\n",
        "\n",
        "def safe_html_display(user_input: str):\n",
        "    \"\"\"Safely display user input in HTML by escaping special characters.\"\"\"\n",
        "    escaped_input = html.escape(user_input)\n",
        "    return HTML(f\"<p>{escaped_input}</p>\")\n",
        "\n",
        "# For untrusted content, prefer Text display\n",
        "def display_untrusted(content: str):\n",
        "    \"\"\"Display untrusted content safely without HTML rendering.\"\"\"\n",
        "    return Text(content)\n",
        "\n",
        "# Usage\n",
        "# user_input = \"<script>alert('xss')</script>\"\n",
        "# safe_html_display(user_input)  # Escapes HTML\n",
        "# display_untrusted(user_input)   # No HTML rendering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. PII Protection\n",
        "\n",
        "✅ **GOOD**: Use placeholder values and never commit real PII"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use placeholders for examples\n",
        "EXAMPLE_EMAIL = \"user@example.com\"  # Placeholder only\n",
        "EXAMPLE_SSN = \"***-**-****\"\n",
        "EXAMPLE_PHONE = \"555-555-5555\"\n",
        "\n",
        "# For real data, load from environment\n",
        "user_email = os.getenv('USER_EMAIL', 'user@example.com')\n",
        "\n",
        "# Never print PII in outputs\n",
        "print(f\"Processing data for user: {user_email[:3]}***@***\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Secure Serialization\n",
        "\n",
        "✅ **GOOD**: Use JSON instead of pickle when possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Safe serialization with JSON\n",
        "data = {\n",
        "    'model_params': {'lr': 0.001, 'epochs': 100},\n",
        "    'metrics': {'accuracy': 0.95, 'loss': 0.05}\n",
        "}\n",
        "\n",
        "# Save safely\n",
        "with open('config.json', 'w') as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "# Load safely\n",
        "with open('config.json', 'r') as f:\n",
        "    loaded_data = json.load(f)\n",
        "\n",
        "print(\"Data loaded securely using JSON\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Input Validation\n",
        "\n",
        "✅ **GOOD**: Always validate user input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def validate_email(email_addr: str) -> bool:\n",
        "    \"\"\"Validate email format.\"\"\"\n",
        "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
        "    return bool(re.match(pattern, email_addr))\n",
        "\n",
        "def validate_age(age: int) -> bool:\n",
        "    \"\"\"Validate age range.\"\"\"\n",
        "    return 0 <= age <= 120\n",
        "\n",
        "def safe_eval(expression: str):\n",
        "    \"\"\"Safely evaluate literal expressions.\"\"\"\n",
        "    import ast\n",
        "    try:\n",
        "        return ast.literal_eval(expression)\n",
        "    except (ValueError, SyntaxError):\n",
        "        raise ValueError(\"Invalid expression - only literals allowed\")\n",
        "\n",
        "# Usage\n",
        "# email = input(\"Email: \")\n",
        "# if validate_email(email):\n",
        "#     print(\"Valid email\")\n",
        "\n",
        "# Safe evaluation of user input\n",
        "# result = safe_eval(\"[1, 2, 3]\")  # OK\n",
        "# result = safe_eval(\"__import__('os').system('ls')\")  # Raises ValueError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Output Sanitization\n",
        "\n",
        "✅ **GOOD**: Clear sensitive outputs before sharing notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Before sharing notebooks:\n",
        "# 1. Clear all outputs: Cell → All Output → Clear\n",
        "# 2. Or use command line:\n",
        "#    jupyter nbconvert --clear-output --inplace notebook.ipynb\n",
        "\n",
        "# For programmatic output clearing:\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Process sensitive data\n",
        "sensitive_result = \"secret data\"\n",
        "\n",
        "# Clear output before committing\n",
        "clear_output(wait=False)\n",
        "print(\"Processing complete (sensitive data cleared)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Error Handling\n",
        "\n",
        "✅ **GOOD**: Handle errors gracefully without exposing sensitive information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def safe_operation(data):\n",
        "    \"\"\"Perform operation with secure error handling.\"\"\"\n",
        "    try:\n",
        "        # Process data\n",
        "        result = process_data(data)\n",
        "        return result\n",
        "    except ValueError as e:\n",
        "        # Log error without exposing sensitive details\n",
        "        print(f\"Validation error: {type(e).__name__}\")\n",
        "        # Don't expose full traceback or sensitive data\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        # Generic error handling\n",
        "        print(f\"Operation failed: {type(e).__name__}\")\n",
        "        return None\n",
        "\n",
        "# Don't do this:\n",
        "# try:\n",
        "#     result = api.call(api_key)\n",
        "# except Exception as e:\n",
        "#     print(f\"Error: {e}\")  # Might expose API key in error message!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Security Checklist Before Sharing Notebooks\n",
        "\n",
        "Before committing or sharing your notebook:\n",
        "\n",
        "- [ ] Clear all cell outputs\n",
        "- [ ] Remove hardcoded credentials\n",
        "- [ ] Remove PII (emails, SSNs, phone numbers, etc.)\n",
        "- [ ] Replace real data with example/placeholder values\n",
        "- [ ] Remove absolute file paths\n",
        "- [ ] Check for API keys in code or outputs\n",
        "- [ ] Verify no shell commands with sensitive data\n",
        "- [ ] Run PyGuard security scan\n",
        "- [ ] Review .gitignore for .env files\n",
        "- [ ] Test notebook runs from clean state\n",
        "\n",
        "## Run PyGuard Security Scan\n",
        "\n",
        "```bash\n",
        "# Scan this notebook for security issues\n",
        "python -c \"\n",
        "from pyguard.lib.notebook_security import scan_notebook\n",
        "issues = scan_notebook('secure_notebook_example.ipynb')\n",
        "print(f'Found {len(issues)} security issues')\n",
        "\"\n",
        "```\n",
        "\n",
        "Expected result: **0 issues** (this notebook follows all best practices!)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
